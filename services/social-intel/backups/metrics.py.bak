"""
Prometheus metrics for the Social Intelligence service.
"""

import time
from prometheus_client import Counter, Histogram, Gauge

# Request metrics
SI_REQUESTS_TOTAL = Counter(
    'si_requests_total',
    'Total number of requests to the Social Intelligence API',
    ['endpoint', 'status']
)

# Latency metrics (in seconds)
SI_LATENCY_SECONDS = Histogram(
    'si_latency_seconds',
    'Request latency in seconds',
    ['endpoint'],
    buckets=[0.05, 0.1, 0.2, 0.4, 0.8, 2]
)

# Worker lag metrics (in seconds)
WORKER_LAG_SECONDS = Gauge(
    'si_worker_lag_seconds',
    'Lag time for workers in seconds'
)

# Database metrics
DB_QUERY_SECONDS = Histogram(
    'si_db_query_seconds',
    'Database query time in seconds',
    ['operation'],
    buckets=[0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0]
)

# Social Intel specific metrics
NICHE_SCOUT_RESULTS_COUNT = Gauge(
    'si_niche_scout_results',
    'Number of niche results returned'
)

NICHE_OPPORTUNITY_SCORE = Histogram(
    'si_niche_opportunity_score',
    'Distribution of niche opportunity scores',
    buckets=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.5, 2.0, 5.0]
)

class LatencyTimer:
    """Context manager for timing operations and recording metrics."""
    
    def __init__(self, metric, labels=None):
        self.metric = metric
        self.labels = labels or {}
        self.start_time = None
        
    def __enter__(self):
        self.start_time = time.time()
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        duration = time.time() - self.start_time
        if isinstance(self.metric, Histogram):
            self.metric.labels(**self.labels).observe(duration)
        elif isinstance(self.metric, Gauge):
            self.metric.labels(**self.labels).set(duration)
        return False  # Don't suppress exceptions